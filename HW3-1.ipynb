{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dacc82b3-0d83-4dc6-9eb8-013db049842a",
   "metadata": {},
   "source": [
    "## PS3 Programming exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577d5d6-084e-48ed-ba14-71817479e4e8",
   "metadata": {},
   "source": [
    "- In this exercise, you will find the distance metric between the sequenses of images using the geometry of Grassmannian manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcba95-5ba1-47a1-9073-4aaee5e16ec9",
   "metadata": {},
   "source": [
    "### Dependency and initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd49d5c-8279-42dd-a478-805589bdde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac904f33-a843-4d93-9bf9-decbec1f9ea9",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0450e4-6a53-446f-a70c-127e710a2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MNIST_data(n_data=6000, sequence_length=10, shuffle=True):\n",
    "    \n",
    "    assert n_data % 10 == 0, f'n_data should be divisible by 10, got {n_data}'\n",
    "    assert n_data <= 60000, f'n_data*set_size should be lower than 60000, got {n_data}.'\n",
    "    \n",
    "    n_data_per_label = int(n_data/10)\n",
    "    \n",
    "    dataset = MNIST(root='.', download=True)\n",
    "\n",
    "    dataset.train = True\n",
    "    data1, targets1 = dataset._load_data()\n",
    "    dataset.train = False\n",
    "    data2, targets2 = dataset._load_data()\n",
    "\n",
    "    data = (torch.cat([data1, data2], dim=0).to(torch.float32) / 255).unsqueeze(1)\n",
    "    targets = torch.cat([targets1, targets2], dim=0)\n",
    "    \n",
    "    data_ = []\n",
    "    targets_ = []\n",
    "\n",
    "    for label in range(10):\n",
    "        data_i = data[targets==label][:n_data_per_label*sequence_length]\n",
    "\n",
    "        dims = data_i.shape[1:]\n",
    "        data_i = data_i.reshape(n_data_per_label, sequence_length, *dims).permute(0, 2, 3, 4, 1)\n",
    "        targets_i = torch.ones(n_data_per_label) * label\n",
    "\n",
    "        data_.append(data_i)\n",
    "        targets_.append(targets_i)\n",
    "\n",
    "    data = torch.cat(data_, dim=0)\n",
    "    targets = torch.cat(targets_, dim=0)\n",
    "    \n",
    "    if shuffle:\n",
    "        shuffle_idx = torch.randperm(len(data))\n",
    "        data = data[shuffle_idx]\n",
    "        targets = targets[shuffle_idx]\n",
    "    \n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d37f6b-b893-4011-aab3-83d0a52a1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary adjustments based on your computational resources (memory, cpu, etc).\n",
    "\n",
    "n_data = 600             # Total number of data points (sequences) in the dataset, the code might be slow for n_data > 1000\n",
    "sequence_length = 10     # The length of each data point (sequence). \n",
    "\n",
    "data, targets = load_MNIST_data(n_data=n_data, sequence_length=sequence_length, shuffle=True)\n",
    "data.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260b4c0-d6e0-4a3f-81e2-f08e57bf836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some data points. Each row of the plot represents a single data point (sequence). \n",
    "img = make_grid(data[:10].permute(0, 4, 1, 2, 3).flatten(0, 1), nrow=sequence_length, value_range=(0, 1), pad_value=1)\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42310ce2-b97a-4d55-b3f1-12aa8c10af32",
   "metadata": {},
   "source": [
    "### Projection Mapping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0008a-8c91-4adc-a1e9-27bcd5ea5c63",
   "metadata": {},
   "source": [
    "A sequence of images $X_i \\in \\mathbb{R}^{784 \\times \\texttt{sequence\\_length}}$ is represented by a $k$-dimensional linear subspace spanned by an orthogonal basis matrix $Y_i \\in \\mathbb{R}^{784 \\times k}$, s.t. $X_i X_i^T \\approx Y_i \\Lambda_i Y_i^T$, where $\\Lambda_i$, $Y_i$ correspond to the matrices of the $k$ largest eigenvalues and eigenvectors respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb150cb3-5725-48a9-9f4b-98b1236fd83e",
   "metadata": {},
   "source": [
    "#### (a) Calculate $Y_i$ (Hint: use ```torch.linalg.eig()```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2cd40d-e532-4a04-b732-77a5c59c01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The flatten MNIST is 784 dim. vector, so N for the grassmannian manifold Gr(k, N) is 784.\n",
    "# We need to select an approproate value k of Gr(k, N). \n",
    "k = 10 \n",
    "\n",
    "X = data.flatten(1, 3).clone() # Dim. of (n_data, 784, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25be932-c7ef-4873-834d-5d6e035d65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to calculate Lambda, Y\n",
    "# Lambda : Eigenvalues, dim. of (n_data, 784)\n",
    "# Y : Eigenvectors, dim. of (n_data, 784, 784)\n",
    "# the code will be slow.\n",
    "\n",
    "Lambda, Y = ######### CODE TO WRITE #########\n",
    "\n",
    "assert Lambda.shape == (n_data, 784), f'Dimensions mismatch: expected ({n_data}, 784), got {Lambda.shape}'\n",
    "assert Y.shape == (n_data, 784, 784), f'Dimensions mismatch: expected ({n_data}, 784, 784), got {Y.shape}'\n",
    "\n",
    "# Lambda and Y could be complex because of the numerical error\n",
    "Lambda_real = Lambda.real.clone()\n",
    "Y_real = Y.real.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3d97c-64ae-4cbf-9b72-ae455b83878c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Leave only k large eigenvalues in Y_real and Lambda_real\n",
    "\n",
    "Y_low, Lambda_low = ######### CODE TO WRITE #########\n",
    "\n",
    "assert Lambda_low.shape == (n_data, k), f'Dimensions mismatch: expected ({n_data}, {k}), got {Lambda_low.shape}'\n",
    "assert Y_low.shape == (n_data, 784, k), f'Dimensions mismatch: expected ({n_data}, 784, {k}), got {Y_low.shape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d93676-d6c4-438c-996e-ff006d5ea224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check approximation error : XX^T ~ Y \\Lambda Y^T \n",
    "XXT_lowapprox = Y_low @ torch.diag_embed(Lambda_low) @ Y_low.transpose(1, 2)\n",
    "print(f'Approximation Error: {torch.dist(XXT, XXT_lowapprox)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47981395-751d-4f5f-bb23-9087d7536d34",
   "metadata": {},
   "source": [
    "#### (b) Calculate Projection Mapping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd7e3b-4c72-4514-9b68-592bfd2b1084",
   "metadata": {},
   "source": [
    "- An element of $\\mathcal{Gr}(k, N)$ is a linear subspace span($Y_i$), which is spanned by its orthonomal basis matrix $Y_i$.\n",
    "- The elements on the Grassmannian manifold can be represented with the projection mapping $\\Phi(Y_i)=Y_i Y_i^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41aa66-7f0b-4057-b14f-40ee74ee92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate projection matric P \n",
    "# P : projection matrices, dim. of (Batch, 784, 784)\n",
    "\n",
    "P = ######### CODE TO WRITE #########\n",
    "\n",
    "assert P.shape == (n_data, 784, 784), f'Dimensions mismatch: expected ({n_data}, 784, 784), got {P.shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72320546-a625-4d16-9a6c-22ed6f0de492",
   "metadata": {},
   "source": [
    "#### (c) Training K-Neighbors classifier for MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce27b1-d4ec-4a28-8ba9-5c972db01370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.7\n",
    "\n",
    "idx_ = torch.randperm(n_data)\n",
    "train_mask = idx_[:int(n_data*train_test_split)]\n",
    "test_mask = idx_[int(n_data*train_test_split):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b1e51-12f8-4927-ae2d-29a91e1f101c",
   "metadata": {},
   "source": [
    "##### Use Euclidean distances (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7d10a-ae1c-4c8c-9c4a-76e65bd93630",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_KNC_euclidean = X.flatten(1, 2).clone().numpy()\n",
    "Y_KNC_euclidean = targets.clone().numpy()\n",
    "\n",
    "X_train_euclidean = X_KNC_euclidean[train_mask]\n",
    "Y_train_euclidean = Y_KNC_euclidean[train_mask]\n",
    "\n",
    "X_test_euclidean = X_KNC_euclidean[test_mask]\n",
    "Y_test_euclidean = Y_KNC_euclidean[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e75100-d1d1-4246-ac11-b6af9af26758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_euclidean = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier_euclidean.fit(X_train_euclidean, Y_train_euclidean)\n",
    "accu_euclidean = classifier_euclidean.score(X_test_euclidean, Y_test_euclidean)\n",
    "print(f'Accuracy (Euclidean): {accu_euclidean*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a55998-85f5-4c46-b7c8-6dd3a1ccfcc4",
   "metadata": {},
   "source": [
    "##### Use geodesic distances on Grassmannian manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0c048-337f-4cae-a2c3-618855b60fc1",
   "metadata": {},
   "source": [
    "- Since the projection matrix $Y_i Y_i^T$ is a $D \\times D$ symmetric matrix, a natural choice of inner product is $d(Y_1 Y_1^T, Y_2 Y_2^T) = \\frac{1}{\\sqrt{2}} ||Y_1 Y_1^T-Y_2 Y_2^T||_F$ where $||\\cdot||_F$ denotes the maxtrix Frobenius norm.\n",
    "- This is also called Projection Metric, and is able to approximate the true Grassmannian geodesic distance up to scale of $\\sqrt{2}$. (one of the most popular metrics on the Grassmannian manifold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8307e-c87b-4d67-981b-48bdd53af1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X_KNC for KNeighborsClassifier that uses geodesic distances on Grassmannian manifold\n",
    "# X_KNC_geodesic : numpy array, dim. of (n_data, vector_dim)\n",
    "\n",
    "X_KNC_geodesic = ######### CODE TO WRITE #########\n",
    "\n",
    "Y_KNC_geodesic = targets.clone().numpy()\n",
    "\n",
    "X_train_geodesic = X_KNC_geodesic[train_mask]\n",
    "Y_train_geodesic = Y_KNC_geodesic[train_mask]\n",
    "\n",
    "X_test_geodesic = X_KNC_geodesic[test_mask]\n",
    "Y_test_geodesic = Y_KNC_geodesic[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fe809-67c3-4b6d-8ba4-c53f766ce018",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_geodesic = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier_geodesic.fit(X_train_geodesic, Y_train_geodesic)\n",
    "accu_geodesic = classifier_geodesic.score(X_test_geodesic, Y_test_geodesic)\n",
    "print(f'Accuracy (Geodesic): {accu_geodesic*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91a033-20b7-440e-9f16-805574b20553",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Huang, Zhiwu, et al. \"Projection metric learning on Grassmann manifold with application to video based face recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.\n",
    "- Hamm, Jihun, and Daniel D. Lee. \"Grassmann discriminant analysis: a unifying view on subspace-based learning.\" Proceedings of the 25th international conference on Machine learning. 2008.\n",
    "- Harandi, Mehrtash, et al. \"Dictionary learning and sparse coding on Grassmann manifolds: An extrinsic solution.\" Proceedings of the IEEE international conference on computer vision. 2013.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLIsoLR",
   "language": "python",
   "name": "dlisolr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
