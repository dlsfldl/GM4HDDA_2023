{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS3-2 Programming exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "# if you don't have gpu, \n",
    "# you can set device='cpu'\n",
    "device = f'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this exercise, you will implement isometric representation learning algorithms for the hemisphere surface.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For the hemisphere manifold $\\mathcal{M}:=\\{(x,y,z)\\in\\mathbb{R}^{3} | x^2+y^2+z^2=1, z>0\\}$, we will consider a local coordinate system $f:\\mathbb{R}^2 \\to \\mathcal{M}$ such that $f(x,y) = (x,y,\\sqrt{1-x^2-y^2})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_coordinates_forward(z):\n",
    "    '''\n",
    "    z: torch.tensor whose size = (n, 2)\n",
    "    '''\n",
    "    return torch.cat([z, torch.sqrt(1-torch.norm(z, dim=1, keepdim=True)**2)], dim=1)\n",
    "    \n",
    "def local_coordinates_inverse(x):\n",
    "    '''\n",
    "    x: torch.tensor whose size = (n, 3)\n",
    "    '''\n",
    "    return x[:, :2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's visualize this coordinate system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "r = torch.sqrt(0.9999*torch.rand(10000, 1))\n",
    "theta = 2*np.pi*torch.rand(10000, 1)\n",
    "\n",
    "z = torch.cat(\n",
    "    [r*torch.cos(theta), r*torch.sin(theta)], dim=1)\n",
    "\n",
    "x = local_coordinates_forward(z)\n",
    "\n",
    "def color_map(x):\n",
    "    # return torch.arctan(x[:, 2]/torch.norm(x[:, :2], dim=1))\n",
    "    return x[:, 2]\n",
    "\n",
    "ax.scatter(x[:, 0], x[:, 1], x[:, 2], c=color_map(x), s=1)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('Hemisphere')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "z = local_coordinates_inverse(x)\n",
    "ax.scatter(z[:, 0], z[:, 1], c=color_map(x), s=1)\n",
    "ax.set_title('Local coordinates (viewed from above)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Write the code for computing the Riemannian metric expressed in the above coordinate system (assume that the sphere lies inside Euclidean space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(z):\n",
    "    '''\n",
    "    z:      torch.tensor whose size = (n, 2)\n",
    "    out:    torch.tensor whose size = (n, 2, 2)\n",
    "    '''\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the below code block to visualze the Riemannian metrics as equidistant ellipses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import PD_metric_to_ellipse\n",
    "\n",
    "points = []\n",
    "for i in range(10):\n",
    "    for j in range(4):\n",
    "        theta = np.pi * 2 / 10 * i\n",
    "        radius = 0.3 + 0.2 * j\n",
    "        points.append([radius * np.cos(theta), radius * np.sin(theta)])\n",
    "points = torch.Tensor(points)\n",
    "\n",
    "G = metric(points)\n",
    "\n",
    "# draw figures\n",
    "f = plt.figure(figsize=(7,7))\n",
    "ax = plt.gca()\n",
    "for i, g in enumerate(G):\n",
    "    e = PD_metric_to_ellipse(np.linalg.inv(g), points[i,:], 0.2, alpha = 0.3)\n",
    "    ax.add_artist(e)\n",
    "circle = plt.Circle((0, 0), 1, color='tab:red', fill=False)\n",
    "ax.add_patch(circle)\n",
    "ax.set_xlim((-1, 1))\n",
    "ax.set_ylim((-1, 1))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1) Interpret the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now, you will find a near isometric mapping $f$ from the local cooridnate space $U:=\\{z\\in\\mathbb{R}^2|z_1^2+z_2^2 < 1\\}$ assigned with the above metric $G(z)$ to the Euclidean space $\\mathbb{R}^2$ assigned with the identity metric. We will approximate the mapping $f$ with a fully-connected neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First of all, we will try to minimize the follwing loss function: $\\int_U \\sum_{i=1}^{2}(\\lambda_i(J^T J G^{-1}) - 1)^2 \\sqrt{\\det(G)} \\ dz$ where $\\lambda_i(\\cdot)$ denotes the $i$-th eigenvalue and $J$ is the Jacobian of $f$.\n",
    "* To implement the integration, we will use the Monte-Carlo approximation with the uniform distribution on $U$.\n",
    "* We will use one of the standard stochastic gradient decent methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a fully-connected NN model as below (torch.nn.module class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modules import FC_vec\n",
    "model = FC_vec(\n",
    "    in_chan=2,\n",
    "    out_chan=2,\n",
    "    l_hidden=[1024, 1024],\n",
    "    activation=['relu', 'relu'],\n",
    "    out_activation='linear',\n",
    ").to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(10, 2).to(device)\n",
    "out = model(z)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below function can be used to compute the Jacobian of the above NN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_of_f(f, z, create_graph=True):\n",
    "    batch_size, z_dim = z.size()\n",
    "    v = torch.eye(z_dim).unsqueeze(0).repeat(batch_size, 1, 1).view(-1, z_dim).to(z)\n",
    "    z = z.repeat(1, z_dim).view(-1, z_dim)\n",
    "    out = (\n",
    "        torch.autograd.functional.jvp(\n",
    "            f, z, v=v, create_graph=create_graph\n",
    "        )[1].view(batch_size, z_dim, -1).permute(0, 2, 1)\n",
    "    )\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(100, 2).to(device)\n",
    "J = jacobian_of_f(model, z)\n",
    "print(J.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Write the code for the follwing loss function: $\\mathbb{E}_{z \\sim p(z)} [\\sum_{i=1}^{2}(\\lambda_i(J^T J G^{-1}) - 1)^2 \\sqrt{\\det(G)}]$ where $p(z)$ is the uniform distribution on $U$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isometry_loss(f, z_samples):\n",
    "    '''\n",
    "    f:          torch.nn.module class \n",
    "    z_samples:  torch.tensor whose size = (n, 2) \n",
    "    out:        torch.tensor whose size = (1, )\n",
    "    '''\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples from the uniform dist. p(z)\n",
    "def randn_disk(num_samples, device):\n",
    "    r = torch.sqrt(0.9999*torch.rand(num_samples, 1))\n",
    "    theta = 2*np.pi*torch.rand(num_samples, 1)\n",
    "    z_samples = torch.cat(\n",
    "        [r*torch.cos(theta), r*torch.sin(theta)], dim=1).to(device)\n",
    "    return z_samples\n",
    "\n",
    "# monte-carlo estimation of the loss \n",
    "z_samples = randn_disk(1000, device)\n",
    "isometry_loss(model, z_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now you will minimize the above loss function by using torch autograd libs:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "l_losses = []\n",
    "for epoch in range(300):\n",
    "    z_samples = randn_disk(1000, device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = isometry_loss(model, z_samples)\n",
    "    l_losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print(loss.item())\n",
    "isometry = copy.copy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the loss curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('isometry loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(l_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare the local coordinates and the isometric representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "r = torch.sqrt(0.9999*torch.rand(10000, 1))\n",
    "theta = 2*np.pi*torch.rand(10000, 1)\n",
    "\n",
    "z = torch.cat(\n",
    "    [r*torch.cos(theta), r*torch.sin(theta)], dim=1)\n",
    "\n",
    "x = local_coordinates_forward(z)\n",
    "ax.scatter(x[:, 0], x[:, 1], x[:, 2], c=color_map(x), s=1)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('Hemisphere')\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "z = local_coordinates_inverse(x)\n",
    "ax.scatter(z[:, 0], z[:, 1], c=color_map(x), s=1)\n",
    "ax.set_title('Local coordinates (viewed from above)')\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "z_iso = isometry(z.to(device)).detach().cpu()\n",
    "ax.scatter(z_iso[:, 0], z_iso[:, 1], c=color_map(x), s=1)\n",
    "ax.set_title('Near Isometric Representation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) Interpret this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Secondly, we will try to learn the harmonic map with the boundary condition that is $f(z)=z$ for $z\\in\\partial U:=\\{(x,y)\\in\\mathbb{R}^2|x^2+y^2=1\\}$.\n",
    "* The harmonic loss function can be written as $\\int_U \\mathrm{Tr}(J^T J G^{-1})\\sqrt{\\det(G)} \\ dz$ where $J$ is the Jacobian of $f$.\n",
    "* To implement the integration, we will use the Monte-Carlo approximation with the uniform distribution on $U$ as the above.\n",
    "* Again, we will use one of the standard stochastic gradient decent methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Write the code for the follwing loss function: $\\mathbb{E}_{z \\sim p(z)} [\\mathrm{Tr}(J^T J G^{-1})\\sqrt{\\det(G)}]$ where $p(z)$ is the uniform distribution on $U$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_loss(f, z_samples):\n",
    "    '''\n",
    "    f:          torch.nn.module class \n",
    "    z_samples:  torch.tensor whose size = (n, 2) \n",
    "    out:        torch.tensor whose size = (1, )\n",
    "    '''\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) To make a neural network model satisfy the boundary condition, we need an additional loss term. Write the code for the boundary loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_loss(f, z_boundary_samples):\n",
    "    '''\n",
    "    f:                   torch.nn.module class \n",
    "    z_boundary_samples:  torch.tensor whose size = (n, 2) \n",
    "    out:                 torch.tensor whose size = (1, )\n",
    "    '''\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples from the uniform dist. p(z)\n",
    "def randn_disk(num_samples, device):\n",
    "    r = torch.sqrt(0.9999*torch.rand(num_samples, 1))\n",
    "    theta = 2*np.pi*torch.rand(num_samples, 1)\n",
    "    z_samples = torch.cat(\n",
    "        [r*torch.cos(theta), r*torch.sin(theta)], dim=1).to(device)\n",
    "    return z_samples\n",
    "\n",
    "# samples from the uniform dist. on the boundary \\partial U\n",
    "def randn_boundary(num_samples, device):\n",
    "    temp = torch.randn(num_samples, 2).to(device)\n",
    "    z_boundary_samples = temp/torch.norm(temp, dim=1, keepdim=True)\n",
    "    return z_boundary_samples\n",
    "\n",
    "# monte-carlo estimation of the loss \n",
    "z_boundary_samples = randn_boundary(1000, device)\n",
    "boundary_loss(model, z_boundary_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modules import FC_vec\n",
    "model2 = FC_vec(\n",
    "    in_chan=2,\n",
    "    out_chan=2,\n",
    "    l_hidden=[1024, 1024],\n",
    "    activation=['relu', 'relu'],\n",
    "    out_activation='linear',\n",
    ").to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now you will minimize the sum of the harmonic loss and boundary loss by using torch autograd libs:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.0001)\n",
    "\n",
    "l_losses = []\n",
    "for epoch in range(300):\n",
    "    z_samples = randn_disk(1000, device)\n",
    "    z_boundary_samples = randn_boundary(100, device)\n",
    "    optimizer.zero_grad()\n",
    "    h_loss = harmonic_loss(model2, z_samples)\n",
    "    b_loss = boundary_loss(model2, z_boundary_samples)\n",
    "    loss = h_loss + 100*b_loss\n",
    "    l_losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print(loss.item())\n",
    "harmonic_map = copy.copy(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('harmonic + boundary loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(l_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare the local coordinates, the isometric representation, and the harmonic representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 1, projection='3d')\n",
    "r = torch.sqrt(0.9999*torch.rand(10000, 1))\n",
    "theta = 2*np.pi*torch.rand(10000, 1)\n",
    "\n",
    "z = torch.cat(\n",
    "    [r*torch.cos(theta), r*torch.sin(theta)], dim=1)\n",
    "\n",
    "x = local_coordinates_forward(z)\n",
    "ax.scatter(x[:, 0], x[:, 1], x[:, 2], c=color_map(x), s=1)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('Hemisphere')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 2)\n",
    "z = local_coordinates_inverse(x)\n",
    "ax.scatter(z[:, 0], z[:, 1], c=color_map(x), s=1)\n",
    "ax.set_title('Local coordinates (viewed from above)')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 3)\n",
    "z_iso = isometry(z.to(device)).detach().cpu()\n",
    "ax.scatter(z_iso[:, 0], z_iso[:, 1], c=color_map(x), s=1)\n",
    "ax.set_title('Near Isometric Representation')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 4)\n",
    "z_harmonic = harmonic_map(z.to(device)).detach().cpu()\n",
    "ax.scatter(z_harmonic[:, 0], z_harmonic[:, 1], c=color_map(x), s=1)\n",
    "ax.set_title('Harmonic Representation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Radius comparison')\n",
    "r_upper_view = torch.norm(z, dim=1).sort(descending=True).values\n",
    "r_iso = torch.norm(z_iso, dim=1).sort(descending=True).values\n",
    "r_iso = r_iso/r_iso.max()\n",
    "r_harmonic = torch.norm(z_harmonic, dim=1).sort(descending=True).values\n",
    "r_harmonic = r_harmonic/r_harmonic.max()\n",
    "\n",
    "plt.plot(r_upper_view, r_upper_view, c='tab:orange', label='upper_view')\n",
    "plt.plot(r_upper_view, r_iso, c='tab:blue', label='isometric')\n",
    "plt.plot(r_upper_view, r_harmonic, c='tab:red', label='harmonic')\n",
    "plt.scatter([0, 1], [0, 1], c='k')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3) How are they different? Compare and analyze the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now, you are going to study how these types of geometry-preserving loss functions can be used for manifold representation learning problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As a simple toy case, we will consider the problem of learning a two-dimensional manifold of three-dimensional data points by using an autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D data generation \n",
    "X = torch.linspace(-1, 1, 60)\n",
    "Y = torch.linspace(-1, 1, 60)\n",
    "X, Y = torch.meshgrid(X, Y)\n",
    "Z = 4*Y**4\n",
    "\n",
    "x = torch.cat([\n",
    "    X.reshape(-1, 1),\n",
    "    Y.reshape(-1, 1),\n",
    "    Z.reshape(-1, 1)\n",
    "], dim=1)\n",
    "\n",
    "def color_map2(x):\n",
    "    return x[:, 2]\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax.scatter(x[:, 0], x[:, 1], x[:, 2], c=color_map2(x), s=10)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('2D Flat Manifold in 3D Space')\n",
    "ax.view_init(50, 30)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's train an autoencoder with two-dimensional latent space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model define \n",
    "from models.ae import AE\n",
    "\n",
    "encoder = FC_vec(\n",
    "    in_chan=3,\n",
    "    out_chan=2,\n",
    "    l_hidden=[512, 512],\n",
    "    activation=['relu', 'relu'],\n",
    "    out_activation='linear',\n",
    ")\n",
    "decoder = FC_vec(\n",
    "    in_chan=2,\n",
    "    out_chan=3,\n",
    "    l_hidden=[512, 512],\n",
    "    activation=['relu', 'relu'],\n",
    "    out_activation='linear',\n",
    ")\n",
    "ae = AE(encoder, decoder).to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train autoencoder\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=0.0001)\n",
    "\n",
    "l_losses = []\n",
    "for epoch in range(100):\n",
    "    for batch in x.split(100):\n",
    "        optimizer.zero_grad()\n",
    "        recon = ae(batch.to(device))\n",
    "        loss = ((recon - batch.to(device))**2).mean()\n",
    "        l_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%50 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's visaulize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "ax.scatter(x[:, 0], x[:, 1], x[:, 2], c=color_map2(x), s=10)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('2D Flat Manifold in 3D Space')\n",
    "ax.view_init(50, 30)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ae_z = ae.encode(x.to(device)).detach().cpu()\n",
    "ax.scatter(ae_z[:, 0], ae_z[:, 1], c=color_map2(x), s=10)\n",
    "ax.set_title('2D Latent Space (vanilla AE)')\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "recon = ae(x.to(device)).detach().cpu()\n",
    "ax.scatter(recon[:, 0], recon[:, 1], recon[:, 2], c=color_map2(recon), s=10)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('Learned Manifold (vanilla AE)')\n",
    "ax.view_init(50, 30)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4) Interpret the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, let's train an autoencoder with two-dimensional latent space, but this time with the isometric regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model define \n",
    "from models.ae import AE\n",
    "\n",
    "encoder = FC_vec(\n",
    "    in_chan=3,\n",
    "    out_chan=2,\n",
    "    l_hidden=[512, 512],\n",
    "    activation=['relu', 'relu'],\n",
    "    out_activation='linear',\n",
    ")\n",
    "decoder = FC_vec(\n",
    "    in_chan=2,\n",
    "    out_chan=3,\n",
    "    l_hidden=[512, 512],\n",
    "    activation=['relu', 'relu'],\n",
    "    out_activation='linear',\n",
    ")\n",
    "irae = AE(encoder, decoder).to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Write the code for the isometry loss function for the decoder mapping $f:\\mathbb{R}^{2} \\to \\mathbb{R}^{3}$ (assume both spaces $\\mathbb{R}^{2}$ and $\\mathbb{R}^3$ are assigned with the identity metrics).\n",
    "* The loss term can be written as $\\mathbb{E}_{z \\sim p(z)}[\\sum_{i=1}^{2} (\\lambda_i(J^TJ)-1)^2] = \\mathbb{E}_{z\\sim p(z)}[\\mathrm{Tr}((J^TJ)^2)-2 \\ \\mathrm{Tr}(J^TJ)+2]$ where $p(z)$ is the latent space data distribution and $J$ is the Jacobian of the decoder.\n",
    "* To estimate the trace of $A$, you are recommened to use the Hutchinsonâ€™s Trace Estimator, i.e., $\\mathrm{Tr}(A)\\approx \\mathbb{E}_{v \\sim \\mathcal{N}(0, 1)}[v^TAv]$ where $\\mathcal{N}(0, 1)$ is the standard normal distribution. \n",
    "* Note that using one sample for $v \\sim \\mathcal{N}(0,1)$ is enough for the trace estimation in SGD-based NN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_isometry_loss(decoder, z):\n",
    "    '''\n",
    "    decoder:    torch.nn.module class \n",
    "    z:          torch.tensor whose size = (n, 2) \n",
    "    out:        torch.tensor whose size = (1, )\n",
    "    '''\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train autoencoder\n",
    "optimizer = torch.optim.Adam(irae.parameters(), lr=0.0001)\n",
    "\n",
    "l_losses = []\n",
    "for epoch in range(200):\n",
    "    for batch in x.split(100):\n",
    "        optimizer.zero_grad()\n",
    "        z_irae = irae.encode(batch.to(device))\n",
    "        recon = irae.decode(z_irae)\n",
    "        recon_loss = ((recon - batch.to(device))**2).mean()\n",
    "        \n",
    "        ### latent data augmentation ###\n",
    "        # We want the isometric regularization effect to be applied for in-between data regions as well\n",
    "        bs = len(z_irae)\n",
    "        z_perm = z_irae[torch.randperm(bs)]\n",
    "        alpha = torch.rand(bs).unsqueeze(1).to(device)\n",
    "        z_augmented = alpha*z_irae + (1-alpha)*z_perm\n",
    "        ################################\n",
    "        \n",
    "        iso_loss = decoder_isometry_loss(irae.decoder, z_irae)\n",
    "        loss = recon_loss + 0.2*iso_loss\n",
    "        l_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%20 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 1, projection='3d')\n",
    "ax.scatter(x[:, 0], x[:, 1], x[:, 2], c=color_map2(x), s=10)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('2D Flat Manifold in 3D Space')\n",
    "ax.view_init(50, 30)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "ae_z = ae.encode(x.to(device)).detach().cpu()\n",
    "ax.scatter(ae_z[:, 0], ae_z[:, 1], c=color_map2(x), s=10)\n",
    "ax.set_title('2D Latent Space \\n (vanilla AE)')\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 3, projection='3d')\n",
    "recon = ae(x.to(device)).detach().cpu()\n",
    "ax.scatter(recon[:, 0], recon[:, 1], recon[:, 2], c=color_map2(recon), s=10)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('Learned Manifold \\n (vanilla AE)')\n",
    "ax.view_init(50, 30)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 5)\n",
    "irae_z = irae.encode(x.to(device)).detach().cpu()\n",
    "ax.scatter(irae_z[:, 0], irae_z[:, 1], c=color_map2(x), s=10)\n",
    "ax.set_title('2D Latent Space \\n (Isometrically Regularized  AE)')\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 6, projection='3d')\n",
    "irae_recon = irae(x.to(device)).detach().cpu()\n",
    "ax.scatter(irae_recon[:, 0], irae_recon[:, 1], irae_recon[:, 2], c=color_map2(recon), s=10)\n",
    "xranges = np.ptp(x, axis=0)\n",
    "ax.set_box_aspect(\n",
    "    (xranges[0].item(), xranges[1].item(), xranges[2].item())\n",
    ")\n",
    "ax.set_title('Learned Manifold \\n (Isometrically Regularized AE)')\n",
    "ax.view_init(50, 30)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5) Interpret the results. Compare between the vanilla AE and isometrically regularized AE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can find many more advanced usages of the isometric loss and harmonic loss functions.  \n",
    "* One particular example usage in autoencoder representation learning can be found in the paper \"Regularized Autoencoders for Isometric Representation Learning (ICLR 2022, Y.H. Lee et al.)\". \n",
    "* For those who are interested in details, we include the git link: https://github.com/Gabe-YHLee/IRVAE-public. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
